{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Semantic Kernel with MCP Servers\n",
    "\n",
    "In this notebook, we'll connect a simple SK Agent to an MCP Server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìã Prerequisites & Configuration\n",
    "\n",
    "### üîß **Environment Setup**\n",
    "1. **Copy the environment file**:\n",
    "   ```bash\n",
    "   cp .env.example .env\n",
    "   ```\n",
    "\n",
    "2. **Edit `.env` file** with your actual credentials:\n",
    "   - Azure OpenAI endpoint, API key, and deployment name\n",
    "   - OR regular OpenAI API key\n",
    "\n",
    "3. **Start the MCP server** (see instructions below)\n",
    "\n",
    "### üóÑÔ∏è **Database Setup**\n",
    "The MCP server uses a SQLite database (`contoso.db`) that should be in the same directory.\n",
    "\n",
    "### ‚ö° **Quick Start**\n",
    "The notebook will automatically load configuration from your `.env` file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's start our MCP server.\n",
    "\n",
    "Open a new terminal and run:\n",
    "\n",
    "using uv:\n",
    "```shell\n",
    "cd 03-semantic-kernel-mcp\\\n",
    "uv run --prerelease=allow mcp_server.py\n",
    "```\n",
    "\n",
    "using pip:\n",
    "```shell\n",
    "pip install fastmcp\n",
    "cd .\\03-semantic-kernel-mcp\\\n",
    "python .\\mcp_server.py\n",
    "```\n",
    "\n",
    "The server should come up like this:\n",
    "\n",
    "```\n",
    "INFO:     Started server process [49488]\n",
    "INFO:     Waiting for application startup.\n",
    "INFO:     Application startup complete.\n",
    "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n",
    "```\n",
    "\n",
    "Great, ready to go, let's connect SK to it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ServiceInitializationError",
     "evalue": "chat_deployment_name is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mServiceInitializationError\u001b[39m                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m contoso_mcp_plugin.connect()\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Now create our agent and plug in the MCP plugin\u001b[39;00m\n\u001b[32m     18\u001b[39m agent = ChatCompletionAgent(\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     service=\u001b[43mAzureChatCompletion\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m     20\u001b[39m     name=\u001b[33m\"\u001b[39m\u001b[33mChatBot\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     21\u001b[39m     instructions=\u001b[33m\"\u001b[39m\u001b[33mYou are a helpful assistant. You can use multiple tools to find information \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     22\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mand answer questions. Review the tools available under the MCPTools plugin \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     23\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mand use them as needed. You can also ask clarifying questions if the user is not clear.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     24\u001b[39m     plugins=[contoso_mcp_plugin],\n\u001b[32m     25\u001b[39m )\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# Same as prior in our workshop \u001b[39;00m\n\u001b[32m     28\u001b[39m thread: ChatHistoryAgentThread = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jangezels\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\semantic_kernel\\connectors\\ai\\open_ai\\services\\azure_chat_completion.py:99\u001b[39m, in \u001b[36mAzureChatCompletion.__init__\u001b[39m\u001b[34m(self, service_id, api_key, deployment_name, endpoint, base_url, api_version, ad_token, ad_token_provider, token_endpoint, default_headers, async_client, env_file_path, env_file_encoding, instruction_role)\u001b[39m\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ServiceInitializationError(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to validate settings: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m azure_openai_settings.chat_deployment_name:\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ServiceInitializationError(\u001b[33m\"\u001b[39m\u001b[33mchat_deployment_name is required.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    101\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\n\u001b[32m    102\u001b[39m     deployment_name=azure_openai_settings.chat_deployment_name,\n\u001b[32m    103\u001b[39m     endpoint=azure_openai_settings.endpoint,\n\u001b[32m   (...)\u001b[39m\u001b[32m    114\u001b[39m     instruction_role=instruction_role,\n\u001b[32m    115\u001b[39m )\n",
      "\u001b[31mServiceInitializationError\u001b[39m: chat_deployment_name is required."
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from semantic_kernel.agents import ChatCompletionAgent, ChatHistoryAgentThread\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "from semantic_kernel.connectors.mcp import MCPSsePlugin\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "print(\"üîß Setting up MCP plugin...\")\n",
    "\n",
    "# Set up the SSE plugin for the MCP service.\n",
    "contoso_mcp_plugin = MCPSsePlugin(\n",
    "    name=\"ContosoMCP\",\n",
    "    description=\"Contoso MCP Plugin\",\n",
    "    url=os.getenv(\"MCP_SERVER_URL\", \"http://localhost:8000/sse\"),\n",
    "    headers={\"Content-Type\": \"application/json\"},\n",
    "    timeout=30,\n",
    ")\n",
    "\n",
    "# Connect to MCP server\n",
    "await contoso_mcp_plugin.connect()\n",
    "print(\"‚úÖ MCP plugin connected successfully!\")\n",
    "\n",
    "print(\"\\nü§ñ Setting up Semantic Kernel agent...\")\n",
    "\n",
    "# Configure Azure OpenAI service\n",
    "service = AzureChatCompletion(\n",
    "    endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    deployment_name=os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\"),\n",
    "    api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\", \"2024-02-15-preview\")\n",
    ")\n",
    "\n",
    "# Create the agent with MCP plugin\n",
    "agent = ChatCompletionAgent(\n",
    "    service=service,\n",
    "    name=\"ChatBot\",\n",
    "    instructions=\"You are a helpful assistant. You can use multiple tools to find information \"\n",
    "    \"and answer questions. Review the tools available under the ContosoMCP plugin \"\n",
    "    \"and use them as needed. You can also ask clarifying questions if the user is not clear.\",\n",
    "    plugins=[contoso_mcp_plugin],\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Setup complete! Agent ready to help with customer inquiries.\")\n",
    "\n",
    "# Same as prior in our workshop \n",
    "thread: ChatHistoryAgentThread = None\n",
    "user_messages = [\n",
    "    \"I noticed my last invoice was higher than usual‚Äîcan you help me understand why and what can be done about it?\",\n",
    "    \"My customer id is 42\",\n",
    "    ]\n",
    "\n",
    "for user_message in user_messages:\n",
    "    print(\"*** User:\", user_message)\n",
    "    response = await agent.get_response(messages=user_message, thread=thread)\n",
    "    thread = response.thread\n",
    "    print(\"*** Agent:\", response.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the agent with customer inquiry\n",
    "print(\"üó£Ô∏è  Starting customer conversation...\\n\")\n",
    "\n",
    "# Same as prior in our workshop \n",
    "thread: ChatHistoryAgentThread = None\n",
    "user_messages = [\n",
    "    \"I noticed my last invoice was higher than usual‚Äîcan you help me understand why and what can be done about it?\",\n",
    "    \"My customer id is 42\",\n",
    "]\n",
    "\n",
    "for user_message in user_messages:\n",
    "    print(f\"üë§ User: {user_message}\")\n",
    "    \n",
    "    response = await agent.get_response(messages=user_message, thread=thread)\n",
    "    thread = response.thread\n",
    "    print(f\"ü§ñ Agent: {response.content}\\n\")\n",
    "    print(\"-\" * 80 + \"\\n\")\n",
    "\n",
    "print(\"‚úÖ Conversation complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
